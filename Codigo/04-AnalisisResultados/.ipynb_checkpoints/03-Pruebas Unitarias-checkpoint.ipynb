{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f7733-80b6-46f9-87df-8ccf1b1e4daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5ca557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6456de-8391-4ba8-aa1e-233cc23e2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manejo de Datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boxcox\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from skimage import io\n",
    "\n",
    "#Machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#Librerias estandar (Extras)\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import imageio\n",
    "import cv2\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4405c622-6ce1-457a-85dc-f60a4ae71433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/FinalTesis/Tesis2-DiegoParedes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DEFINIMOS EL PATH DEL PROYECTO \n",
    "\"\"\"\n",
    "with open('../../path_base.txt') as f:\n",
    "    path_base = f.read()\n",
    "path_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4be2163-0bcd-4b60-b514-0bbc099468a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VARIABLES GENERALES\n",
    "\"\"\"\n",
    "\n",
    "path_imagenes = 'F:/GOES/'      \n",
    "\n",
    "products = ['C13','C07','C08']\n",
    "times   = ['10','20','30','40','50','00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637285f8-65b5-4cd8-8206-63f2e07e2296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a075284-940c-4b2b-9be5-09f5ef9d6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testALL(criterio, model):\n",
    "    df = pd.read_csv(f'{path_base}/Archivos/Reportes/Entrenamiento/{model}/Reporte-BEST_{criterio}.csv')\n",
    "    \n",
    "    for i in df.index:\n",
    "        params = {\n",
    "        'idTest'    : df['idTest'][i],\n",
    "        'epoca'     : df['epoca'][i],\n",
    "        'ascending' : False,\n",
    "        'dsTipo'    :'Validacion',\n",
    "        'umbrales'  : [0.5,0.5],\n",
    "        'model'     : model,\n",
    "        'grafica'   : False\n",
    "        }\n",
    "        _, _ = getStats(path_base, params)       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d407b66-3d0d-46b1-8660-67ba01360e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics( HP ):    \n",
    "    redTipo = HP['redTipo']     \n",
    "    lr = HP['lr']    \n",
    "    \n",
    "    if redTipo == 'Clasificacion':    \n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)   \n",
    "        if HP['loss'] == 'binary_crossentropy':\n",
    "            loss_fn= keras.losses.BinaryCrossentropy()\n",
    "        \n",
    "        train_acc_metric = keras.metrics.BinaryCrossentropy()\n",
    "        val_acc_metric = keras.metrics.BinaryCrossentropy()\n",
    "        \n",
    "        \n",
    "        metrics = ['acc', keras.metrics.TruePositives(),\n",
    "                         keras.metrics.TrueNegatives(),\n",
    "                         keras.metrics.FalsePositives(),\n",
    "                         keras.metrics.FalseNegatives()]\n",
    "        \n",
    "\n",
    "    elif redTipo == 'Regresion':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        loss_fn=keras.losses.MeanSquaredError()\n",
    "        train_acc_metric = keras.metrics.MeanSquaredError()\n",
    "        val_acc_metric = keras.metrics.MeanSquaredError()                                             \n",
    "        metrics = ['mse']\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print('No se pudo crear las metricas')\n",
    "        return -1    \n",
    "         \n",
    "        \n",
    "    logs = Callback()\n",
    "    callbacks = [logs]                     \n",
    "  \n",
    "        \n",
    "    metrics = {'optimizer': optimizer, 'loss_fn':loss_fn,'train_acc_metric': train_acc_metric,\n",
    "               'val_acc_metric': val_acc_metric, 'metrics': metrics,'callbacks': callbacks}\n",
    "    \n",
    "    return metrics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35941c82-01c5-4f39-92fe-85c60cfc0778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos un filename tensor en una imagen\n",
    "def read_png_file(item, value, p,run, path_base, products, times):\n",
    "    # imagenData[0] = XO     # imagenData[1] = XA     # imagenData[2] = Fecha\n",
    "    imagenData = tf.strings.split(item['imagen'], sep='--')\n",
    "    size = int(p['margen'][run] / 2)\n",
    "\n",
    "    timeJoin = []\n",
    "    for j in range(p['tiempos'][run]-1,-1,-1):\n",
    "        filename = path_base + 'PNG/' + imagenData[2] + '/' + imagenData[2] + '_' + str(j) + '.png'\n",
    "        \n",
    "        image_string = tf.io.read_file(filename)\n",
    "\n",
    "        img_decoded = tf.io.decode_png(image_string, dtype=tf.uint16, channels=3)\n",
    "        \n",
    "        \n",
    "                \n",
    "        timeJoin.insert(0,img_decoded[int(imagenData[1]) - size:int(imagenData[1]) + size,\n",
    "                                      int(imagenData[0]) - size:int(imagenData[0]) + size,\n",
    "                                      0:p['canales'][run]])\n",
    " \n",
    "        \n",
    "    if p['tiempos'][run]==1:\n",
    "        imagenData = tf.reshape(timeJoin[0],(p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "    else:\n",
    "        if p['meanMatrizImagen']:        \n",
    "            img = tf.reduce_mean( timeJoin , axis=0 )\n",
    "            imagenData = tf.reshape(img,(p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "        else:\n",
    "            img = tf.stack(timeJoin, axis=0)\n",
    "            imagenData = tf.reshape(img,(p['tiempos'][run],p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "        \n",
    "    \n",
    "    \n",
    "    if len(p['inputs']) == 1:\n",
    "        return imagenData, int(value)\n",
    "    \n",
    "    item['imagen'] = imagenData\n",
    "    itemL = []\n",
    "    for inpL in p['inputs']:\n",
    "        itemL.append(item[inpL])\n",
    "    \n",
    "    return tuple(itemL), int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cac5107-dd5f-4ce3-8d80-a6f71df64a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelFile(idModel, epoca):\n",
    "    # Buscamos todos los modelos en el path_base\n",
    "    os.chdir(f'{path_base}/Archivos/Resultados/')\n",
    "    listFiles = list(glob.glob('**/**/**/*.hdf5'))       \n",
    "    \n",
    "    # Seleccionamos el id y epoca\n",
    "    models = [x for x in listFiles if str(idModel) in x] \n",
    "    models = [x for x in models if f'Model_{epoca:02d}_' in x]\n",
    "    \n",
    "    if len(models)<1:\n",
    "        print(f\"ERROR: No se encontro el modelo {idModel} para la epoca {epoca}\")\n",
    "        return\n",
    "    \n",
    "    return models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d15f483-e6c6-4675-91a1-9acfb1ef1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluarModelo(path_base, dsPruebas,modelo, p_train):  \n",
    "    \n",
    "    inputsList = {}\n",
    "    for inp in p_train['inputs']:\n",
    "        inputsList[inp] = dsPruebas[inp].tolist()       \n",
    "\n",
    "    dsP = tf.data.Dataset.from_tensor_slices(((inputsList),dsPruebas[p_train['outputs']].tolist()))      \n",
    "    dsP = dsP.map(lambda x ,y : read_png_file(x,y,p_train,0,path_imagenes,products,times))\n",
    "    dsP = dsP.batch(p_train['batch'])#.prefetch(tf.data.AUTOTUNE)  \n",
    "\n",
    "    hist = modelo.predict(dsP, verbose=1)\n",
    "\n",
    "    hist = pd.DataFrame({'valores': hist.flatten().tolist()})\n",
    "    hist['dato'] = dsPruebas['dato']\n",
    "    hist['clase'] = dsPruebas['clase']\n",
    "    hist['XO'] = dsPruebas['XO']\n",
    "    hist['XA'] = dsPruebas['XA']\n",
    "    hist['fecha'] = dsPruebas['fecha']\n",
    "    hist['lon'] = dsPruebas['longitud']\n",
    "    hist['lat'] = dsPruebas['latitud']\n",
    "    \n",
    "    \n",
    "    hist.to_csv(f'{path_base}/Archivos/Reportes/Pruebas/{p_train[\"epoca\"]}_{p_train[\"idModel\"]}_{p_train[\"dsTipo\"]}.csv', index=False)\n",
    "        \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3096a73c-08d1-4894-b1b2-c886b5b1f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHPModel(params, dfModels, varProject):\n",
    "    \n",
    "    inputs = dfModels['P-inputs'].iloc[0]\n",
    "    inp = inputs[1:-2].replace(\"'\",\"\").replace(' ','').split(',')\n",
    "    HP = {         \n",
    "            # Datos del modelo\n",
    "          'redTipo'  : params['model'], \n",
    "          'inputs'   : inp,\n",
    "          'meanMatrizImagen' : False, \n",
    "          'outputs'  : dfModels['P-outputs'].iloc[0], \n",
    "          'num_class': 2,\n",
    "\n",
    "           # Hiper parametros \n",
    "          'canales'  : [int(dfModels['P-canales'].iloc[0])],\n",
    "          'tiempos'  : [int(dfModels['P-tiempos'].iloc[0])],\n",
    "          'margen'   : [int(dfModels['P-margen'].iloc[0])],\n",
    "          'runs'     : 1,\n",
    "\n",
    "          # Entrenamiento\n",
    "          'batch'    : 32,\n",
    "          'DA'       : True,    \n",
    "          'idModel'  : dfModels['idTest'].iloc[0],\n",
    "          'epoca'    : dfModels['epoca'].iloc[0],\n",
    "          'dsTipo'   : params['dsTipo'],\n",
    "          'lr'       : dfModels['P-lr'].iloc[0],\n",
    "          'loss'     :dfModels['P-loss'].iloc[0]\n",
    "     }\n",
    "    \n",
    "    return HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2302ae-a467-4829-a8ae-647427934725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModels(path_base, params, dfModels=pd.DataFrame(), dfPruebas=pd.DataFrame(), HP={}): \n",
    "\n",
    "    \"\"\" CARGAMOS EL MODELO \"\"\"       \n",
    "    # Buscamos el nombre del modelo \n",
    "    modelFile = getModelFile(HP['idModel'], HP['epoca'])\n",
    "    _modelo = tf.keras.models.load_model(modelFile)      \n",
    "    \n",
    "    print(f\"Se usará inputs: {HP['inputs']} y output: {HP['outputs']}\")    \n",
    "    metricas = getMetrics(HP)    \n",
    "    _modelo.compile(optimizer=metricas['optimizer'],loss=metricas['loss_fn'],metrics=metricas['metrics'],)        \n",
    "\n",
    "\n",
    "    \"\"\" RESULTADOS \"\"\"   \n",
    "    resultado = evaluarModelo(path_base, dfPruebas,_modelo, HP)\n",
    "        \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc2ffcae-f019-4dbf-9457-0f6a8059c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos el DS validacion\n",
    "def getDataset(path_base,params, idProject): \n",
    "    \"\"\" BUSCAMOS EL ARCHIVO DE PROYECTOS \"\"\"\n",
    "    if not idProject:\n",
    "        print(f'ERROR: ID PROJECT no puede ser vacio / nulo: {idProject}')\n",
    "        return \n",
    "    dfP = pd.read_csv(f'{path_base}/Archivos/Reportes/Entrenamiento/{params[\"model\"]}/Proyectos.csv')\n",
    "    dfP = dfP[dfP['idProject'] == idProject]\n",
    "    if dfP.empty:\n",
    "        print(f'ERROR: No se encontro informacion del project: {idProject}')   \n",
    "        return \n",
    "    \n",
    "    \"\"\" BUSCAMOS LOS DATOS DE PRUEBA \"\"\"\n",
    "    dsName = dfP['dsVal'].iloc[0]\n",
    "    dsName = dsName.replace('Validacion',params['dsTipo'])\n",
    "    dfPruebas = pd.read_csv(dsName)\n",
    "\n",
    "    return dfPruebas, dfP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2e1c22-18de-4d7e-8eea-16b6190c7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModel(path_base, p):\n",
    "    # Leemos las estadisticas\n",
    "    dfA = pd.read_csv(f'{path_base}/Archivos/Reportes/Entrenamiento/{p[\"model\"]}/Reporte-TOTAL.csv')\n",
    "    dfA = dfA[(dfA['idTest']==p[\"idTest\"]) & (dfA['epoca']==p[\"epoca\"])]\n",
    "    \n",
    "    dfA = dfA.head(1)\n",
    "    return dfA , dfA['idProject'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52652602-6531-4375-9159-9b6de9aca88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelBuild(path_base, params):\n",
    "    \"\"\" BUSCAMOS EL MODELO A USAR \"\"\"\n",
    "    dfModels, idProject = getBestModel(path_base, params)\n",
    "\n",
    "\n",
    "    \"\"\" BUSCAMOS EL DS A USAR \"\"\"\n",
    "    dfPruebas, varProject = getDataset(path_base,params, idProject)\n",
    "\n",
    "\n",
    "    \"\"\" DEFINIMOS VARIALBES EXTRAS \"\"\"\n",
    "    _HP = getHPModel(params, dfModels, varProject)\n",
    "    \n",
    "    modelFile = getModelFile(_HP['idModel'], _HP['epoca'])\n",
    "    print(modelFile)\n",
    "    _modelo = tf.keras.models.load_model(modelFile)     \n",
    "    \n",
    "    print(f\"Se usará inputs: {_HP['inputs']} y output: {_HP['outputs']}\")    \n",
    "    metricas = getMetrics(_HP)    \n",
    "    _modelo.compile(optimizer=metricas['optimizer'],loss=metricas['loss_fn'],metrics=metricas['metrics'],)  \n",
    "    \n",
    "    return _modelo, dfPruebas, _HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ff6f938-bc44-4c12-9885-f744a9610077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#Transformamos un filename tensor en una imagen\n",
    "def read_img_file(p, path_base, dfPruebas):\n",
    "    \n",
    "    fecha = p['fecha']\n",
    "    x, y = p['XO'], p['XA']\n",
    "    \n",
    "    _df = dfPruebas[(dfPruebas['imagen']==f'{x}--{y}--{fecha}') & (dfPruebas['dato']==p['dato'])]\n",
    "    extras = {}\n",
    "    for add in p['inputs'][1:]:\n",
    "        extras[add] = _df[add].iloc[0]\n",
    "    \n",
    "\n",
    "    margen = int(p['margen'] / 2)\n",
    "    \n",
    "    data = []\n",
    "    for j in range(p['tiempos']-1,-1,-1):         \n",
    "        filename = path_base + 'PNG/' + fecha + '/' + fecha + '_' + str(j) + '.png'\n",
    "        print(filename)\n",
    "        cmi = cv2.imread(filename, cv2.IMREAD_UNCHANGED)#imageio.imread(filename)\n",
    "        \n",
    "        \n",
    "        cropedImg = cmi[y - margen:y + margen, x - margen:x + margen, :p['canales']-1]\n",
    "        \n",
    "        cropedImg = cv2.cvtColor(cropedImg, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        data.insert(0,cropedImg)\n",
    "        \n",
    "    data = np.stack(data, axis=0)\n",
    "    extras['imagen'] = data\n",
    "    return extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5ea837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel_unitario(model, extras, hp):\n",
    "    imagen = extras['imagen']\n",
    "    tipo = '2D' if hp['tiempos'][0] == 1 else '3D'\n",
    "    if tipo == '2D':\n",
    "        return model.predict([np.full((1, imagen.shape[1], imagen.shape[2],imagen.shape[3]),imagen[0]),\n",
    "                        np.full((1,), extras[hp['inputs'][1]]), #umb1\n",
    "                        np.full((1,), float(extras[hp['inputs'][2]])), #dato\n",
    "                        np.full((1,), float(extras[hp['inputs'][3]])) \n",
    "                       ])\n",
    "        \n",
    "    return model.predict([np.full((1, imagen.shape[0], imagen.shape[1],imagen.shape[2], imagen.shape[3]),imagen),\n",
    "                        np.full((1,), extras[hp['inputs'][1]]), #umb1\n",
    "                        np.full((1,), float(extras[hp['inputs'][2]])), #dato\n",
    "                        np.full((1,), float(extras[hp['inputs'][3]])) \n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb12f40",
   "metadata": {},
   "source": [
    "## Pruebas de variacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6da927bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idTest = '20220625_232822'#'20220618_023232' # '20221217_130543'\n",
    "epoca = 38 # 30 #14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a09557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificacion\\RNN\\Clasificacion-20220625_22\\Model_38_LSTM_clase_20220625_232822.hdf5\n",
      "Se usará inputs: ['imagen', 'dato', 'umb1', 'altura'] y output: clase\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'idTest'    : idTest,\n",
    "    'epoca'     : epoca,\n",
    "    'ascending' : False,\n",
    "    'dsTipo'    :'Validacion',\n",
    "    'umbrales'  : [0.50,0.50],\n",
    "    'model'     :'Clasificacion',\n",
    "    'grafica'   : ['dispersion', 'sensibilidad1','sensibilidad2'] #'dispersion','sensibilidad1','sensibilidad2'\n",
    "}\n",
    "model, dfPruebas, _HP = getModelBuild(path_base,params_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e3820d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/GOES/PNG/2021-03-07-16/2021-03-07-16_2.png\n",
      "F:/GOES/PNG/2021-03-07-16/2021-03-07-16_1.png\n",
      "F:/GOES/PNG/2021-03-07-16/2021-03-07-16_0.png\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'inputs':_HP['inputs'],\n",
    "    'fecha': '2021-03-07-16',\n",
    "    'XO': 199,\n",
    "    'XA': 365,\n",
    "    'dato' : 28.3,\n",
    "    'margen':_HP['margen'][0],\n",
    "    'tiempos':_HP['tiempos'][0],\n",
    "    'canales':_HP['canales'][0]        \n",
    "}\n",
    "\n",
    "extras_malos = read_img_file(params, path_imagenes, dfPruebas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7c9cc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/GOES/PNG/2021-11-09-10/2021-11-09-10_2.png\n",
      "F:/GOES/PNG/2021-11-09-10/2021-11-09-10_1.png\n",
      "F:/GOES/PNG/2021-11-09-10/2021-11-09-10_0.png\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'inputs':_HP['inputs'],\n",
    "    'fecha': '2021-11-09-10',\n",
    "    'XO': 418,\n",
    "    'XA': 594,\n",
    "    'dato' : 40.2,\n",
    "    'margen':_HP['margen'][0],\n",
    "    'tiempos':_HP['tiempos'][0],\n",
    "    'canales':_HP['canales'][0]        \n",
    "}\n",
    "\n",
    "extras_buenos = read_img_file(params, path_imagenes, dfPruebas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5bbbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariaciones(extras, model, variacion, n_tests, vars_name, hp):\n",
    "    dif_vars = {}\n",
    "    for var in vars_name:\n",
    "        difs = []\n",
    "        for n in range(n_tests):\n",
    "            _extras =  extras.copy()\n",
    "            _extras[var] =  _extras[var] + (n*variacion)\n",
    "            difs.append(evaluateModel_unitario(model, _extras,hp).flatten()[0])\n",
    "        dif_vars[var] = difs\n",
    "    return pd.DataFrame(dif_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4742bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3af67331",
   "metadata": {},
   "outputs": [],
   "source": [
    "variacion = 0.1\n",
    "n_tests = 100\n",
    "vars_name = ['umb1','dato','altura']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f20f468-cc8c-4562-9f0e-bceaf35127d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 24, 24, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extras_malos['imagen'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9ac55",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PRUEBA (MALO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f8d0389",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_18\" is incompatible with the layer: expected shape=(None, 3, 24, 24, 2), found shape=(None, 3, 24, 24, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mevaluateModel_unitario\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextras_malos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_HP\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m      2\u001b[0m pred[\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mevaluateModel_unitario\u001b[1;34m(model, extras, hp)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tipo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2D\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict([np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m, imagen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], imagen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],imagen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]),imagen[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m      6\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,), extras[hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]]), \u001b[38;5;66;03m#umb1\u001b[39;00m\n\u001b[0;32m      7\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28mfloat\u001b[39m(extras[hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m]])), \u001b[38;5;66;03m#dato\u001b[39;00m\n\u001b[0;32m      8\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28mfloat\u001b[39m(extras[hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m]])) \n\u001b[0;32m      9\u001b[0m                    ])\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimagen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#umb1\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#dato\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_18\" is incompatible with the layer: expected shape=(None, 3, 24, 24, 2), found shape=(None, 3, 24, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = evaluateModel_unitario(model, extras_malos, _HP).flatten()\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a094f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(getVariaciones(extras_malos, model, variacion, n_tests, vars_name, _HP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244dc054",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PRUEBA (CONFORME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = evaluateModel_unitario(model, extras_buenos, _HP).flatten()\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb057f1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_18\" is incompatible with the layer: expected shape=(None, 3, 24, 24, 2), found shape=(None, 3, 24, 24, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m px\u001b[38;5;241m.\u001b[39mline(\u001b[43mgetVariaciones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras_buenos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariacion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvars_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_HP\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36mgetVariaciones\u001b[1;34m(extras, model, variacion, n_tests, vars_name, hp)\u001b[0m\n\u001b[0;32m      6\u001b[0m         _extras \u001b[38;5;241m=\u001b[39m  extras\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      7\u001b[0m         _extras[var] \u001b[38;5;241m=\u001b[39m  _extras[var] \u001b[38;5;241m+\u001b[39m (n\u001b[38;5;241m*\u001b[39mvariacion)\n\u001b[1;32m----> 8\u001b[0m         difs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mevaluateModel_unitario\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extras\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m     dif_vars[var] \u001b[38;5;241m=\u001b[39m difs\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(dif_vars)\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mevaluateModel_unitario\u001b[1;34m(model, extras, hp)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tipo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2D\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict([np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m, imagen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], imagen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],imagen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]),imagen[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m      6\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,), extras[hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]]), \u001b[38;5;66;03m#umb1\u001b[39;00m\n\u001b[0;32m      7\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28mfloat\u001b[39m(extras[hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m]])), \u001b[38;5;66;03m#dato\u001b[39;00m\n\u001b[0;32m      8\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28mfloat\u001b[39m(extras[hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m]])) \n\u001b[0;32m      9\u001b[0m                    ])\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimagen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#umb1\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#dato\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_18\" is incompatible with the layer: expected shape=(None, 3, 24, 24, 2), found shape=(None, 3, 24, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "px.line(getVariaciones(extras_buenos, model, variacion, n_tests, vars_name, _HP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46210e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prueba Mapa de activacion (SOLO CONV3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1540e55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_class_activation_map(model, extras, output_path):   \n",
    "    tipo = '2D'\n",
    "    \n",
    "    imagen = extras['imagen'][0] / 65536\n",
    "    width, height, _ = imagen.shape\n",
    "    config = model.get_config()\n",
    "    inputLayers = []\n",
    "    lastConv_pos = 0\n",
    "    inputs_pos = []\n",
    "    for posLay,layer in enumerate(config['layers']):\n",
    "        if layer['class_name'] == 'InputLayer':\n",
    "            inputLayers.append(layer['name'])\n",
    "            inputs_pos.append(posLay)\n",
    "        if layer['class_name']== f'Conv{tipo}':\n",
    "            lastConv_pos = posLay\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    final_conv_layer = model.layers[lastConv_pos]\n",
    "    \n",
    "    get_output = K.function([model.layers[inputs_pos[0]].input,\n",
    "                             model.layers[inputs_pos[1]].input,\n",
    "                             model.layers[inputs_pos[2]].input,\n",
    "                             model.layers[inputs_pos[3]].input],                             \n",
    "                            final_conv_layer.output)   \n",
    "    \n",
    "    \n",
    "    if tipo == '2D':\n",
    "        conv_outputs =  get_output([np.full((1, imagen.shape[0], imagen.shape[1],imagen.shape[2]),imagen),\n",
    "                    np.full((1,), extras['dato']), #umb1\n",
    "                    np.full((1,), float(extras['umb1'])), #dato\n",
    "                    np.full((1,), float(extras['altura'])) \n",
    "                   ])\n",
    "    else:\n",
    "        conv_outputs =   get_output([np.full((1, imagen.shape[0], imagen.shape[1],imagen.shape[2], imagen.shape[3]),imagen),\n",
    "                        np.full((1,), extras['dato']),\n",
    "                        np.full((1,), float(extras['umb1'])),\n",
    "                        np.full((1,), float(extras['altura']))\n",
    "                       ])\n",
    "    \n",
    "    conv_outputs = conv_outputs[0]\n",
    "    return conv_outputs\n",
    "\n",
    "    #Create the class activation map.\n",
    "    cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape)\n",
    "    target_class = 0\n",
    "    for i, w in enumerate(class_weights[:, target_class]):\n",
    "            cam += w * conv_outputs[:, :, i]\n",
    "    return cam\n",
    "\n",
    "cam_arr = visualize_class_activation_map(model, extras_malos, 'output_cam')\n",
    "cam_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = tf.convert_to_tensor((extras_malos['imagen']) , dtype=tf.int64) \n",
    "params2 = tf.convert_to_tensor((np.full((1,), extras_malos['dato'])) , dtype=tf.int64) \n",
    "params3 = tf.convert_to_tensor((np.full((1,), extras_malos['umb1'])) , dtype=tf.int64) \n",
    "params4 = tf.convert_to_tensor((np.full((1,), extras_malos['altura'])) , dtype=tf.int64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d19dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = '2D'\n",
    "    \n",
    "imagen = extras_malos['imagen'][0] / 65536\n",
    "width, height, _ = imagen.shape\n",
    "config = model.get_config()\n",
    "inputLayers = []\n",
    "lastConv_pos = 0\n",
    "inputs_pos = []\n",
    "for posLay,layer in enumerate(config['layers']):\n",
    "    if layer['class_name'] == 'InputLayer':\n",
    "        inputLayers.append(layer['name'])\n",
    "        inputs_pos.append(posLay)\n",
    "    if layer['class_name']== f'Conv{tipo}':\n",
    "        lastConv_pos = posLay\n",
    "class_weights = model.layers[-1].get_weights()[0]\n",
    "final_conv_layer = model.layers[lastConv_pos]\n",
    "\n",
    "\n",
    "get_output = tf.keras.models.Model(\n",
    "    [model.layers[inputs_pos[0]].input,\n",
    "     model.layers[inputs_pos[1]].input,\n",
    "     model.layers[inputs_pos[2]].input,\n",
    "     model.layers[inputs_pos[3]].input],\n",
    "    [final_conv_layer.output,model.layers[-1].output]\n",
    ")\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    last_conv_layer_output, preds = get_output([(params1,params2,params3,params4)])\n",
    "    \n",
    "    pred_index = tf.argmax(preds[0])\n",
    "    class_channel = preds[:, pred_index]\n",
    "\n",
    "grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "# This is a vector where each entry is the mean intensity of the gradient\n",
    "# over a specific feature map channel\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "last_conv_layer_output = last_conv_layer_output[0]\n",
    "heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "print(heatmap.shape)\n",
    "heatmap = tf.squeeze(heatmap)\n",
    "print(heatmap.shape)\n",
    "# For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "print(heatmap.shape)\n",
    "heatmap = heatmap.numpy()\n",
    "print(heatmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.uint8(255 * heatmap)\n",
    "jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "# Use RGB values of the colormap\n",
    "jet_colors = jet(np.arange(256))[:, :3]\n",
    "jet_heatmap = jet_colors[heatmap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a70e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(jet_heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image with RGB colorized heatmap\n",
    "jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "jet_heatmap = jet_heatmap.resize((imagen.shape[1], imagen.shape[0]))\n",
    "jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a825fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(jet_heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61959839",
   "metadata": {},
   "outputs": [],
   "source": [
    "superimposed_img = jet_heatmap * 0.4 + imagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_path = './cam.jpg'\n",
    "_superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "_superimposed_img.save(cam_path)\n",
    "\n",
    "# Display Grad CAM\n",
    "Image(cam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(imagen[:,:,0])\n",
    "fig.update_layout(width = 300, height = 300,margin = dict(t=0,r=0,b=0,l=0),)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(imagen[:,:,1])\n",
    "fig.update_layout(width = 300, height = 300,margin = dict(t=0,r=0,b=0,l=0),)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d436f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(imagen[:,:,2])\n",
    "fig.update_layout(width = 300, height = 300,margin = dict(t=0,r=0,b=0,l=0),)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6ab07-e84c-4e94-b0a0-7ba4232a8887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031efd0a-03be-4104-9de7-5e313dfe61d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca0c9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OBJETIVO : Realizar pruebas manuales con los mejores modelos escogidos, \n",
    "            de esta forma analizaar su comportamiento con conjunto de datos\n",
    "            personalizados.\n",
    "            \n",
    "\"\"\"\n",
    "Autor='Diego Paredes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84fad3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manejo de Datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "\n",
    "#Machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#Librerias estandar (Extras)\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eec47e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/NewTesis'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DEFINIMOS EL PATH DEL PROYECTO \n",
    "\"\"\"\n",
    "with open('../../path_base.txt') as f:\n",
    "    path_base = f.read()\n",
    "path_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0387f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VARIABLES GENERALES\n",
    "\"\"\"\n",
    "\n",
    "path_imagenes = 'F:/GOES/'      \n",
    "\n",
    "products = ['C07','C08','C13']\n",
    "times   = ['10','20','30','40','50','00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a1a70cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearModelo2D(p,run):    \n",
    "    # Imagen\n",
    "    input_1 = tf.keras.layers.Input(shape=(p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "    \n",
    "    # Convulutional layers\n",
    "    rescaling = tf.keras.layers.Rescaling(1./65536)(input_1)\n",
    "    conv2d_1 = tf.keras.layers.Conv2D(128, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(rescaling)\n",
    "    mxPool_1 = tf.keras.layers.MaxPooling2D()(conv2d_1)\n",
    "    dropout_1  = tf.keras.layers.Dropout(0.2)(mxPool_1)\n",
    "    \n",
    "    conv2d_2 = tf.keras.layers.Conv2D(64, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_1)\n",
    "    mxPool_2 = tf.keras.layers.MaxPooling2D()(conv2d_2)\n",
    "    dropout_2  = tf.keras.layers.Dropout(0.1)(mxPool_2)\n",
    "    \n",
    "    #conv2d_3 = tf.keras.layers.Conv2D(32, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_1)\n",
    "    #mxPool_3 = tf.keras.layers.MaxPooling2D()(conv2d_3)\n",
    "    #dropout_3  = tf.keras.layers.Dropout(0.2)(mxPool_3)\n",
    "    \n",
    "    #conv2d_4 = tf.keras.layers.Conv2D(64, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_3)\n",
    "    #mxPool_4 = tf.keras.layers.MaxPooling2D()(conv2d_4)\n",
    "    #dropout_4  = tf.keras.layers.Dropout(0.2)(mxPool_4)\n",
    "    \n",
    "    conv2d_5 = tf.keras.layers.Conv2D(32, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_2)\n",
    "    \n",
    "    \n",
    "    # Flatten layer :\n",
    "    flatten = tf.keras.layers.Flatten()(conv2d_5)\n",
    "    \n",
    "    final = flatten\n",
    "    listConcat = [flatten]\n",
    "    listInputs = [input_1]\n",
    "    \n",
    "    if len(p['inputs'])>1:\n",
    "        #Agregamos los otros atrbutos        \n",
    "        for attr in p['inputs'][1:]:\n",
    "            # The other input\n",
    "            input_x = tf.keras.layers.Input(shape=(1,))\n",
    "            listConcat.append(input_x)\n",
    "            listInputs.append(input_x)\n",
    "\n",
    "            \n",
    "        # Concatenate\n",
    "        final = tf.keras.layers.Concatenate()(listConcat)\n",
    "        \n",
    "    dense_1 = tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu)(final)\n",
    "    #dense_2 = tf.keras.layers.Dense(units=16, activation=tf.keras.activations.relu)(dense_1)\n",
    "    dense_3 = tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu)(dense_1)\n",
    "    \n",
    "        \n",
    "    # output\n",
    "    if p['redTipo'] == 'regresion':\n",
    "        output = tf.keras.layers.Dense(units=1)(dense_3)\n",
    "        dimOutput = 1\n",
    "    elif p['redTipo'] == 'clasificacion':\n",
    "        output = tf.keras.layers.Dense(units=1,activation=tf.keras.activations.sigmoid)(dense_3)#units=1, activation=tf.keras.activations.relu)(dense_3)\n",
    "        dimOutput = 2\n",
    "    else:\n",
    "        print(f\"No se pudo crear el modelo outputs no esta bien definido {p['redTipo']}\")\n",
    "        return -1      \n",
    "    \n",
    "\n",
    "    full_model = tf.keras.Model(inputs=listInputs, outputs=[output])\n",
    "        \n",
    "    #print(full_model.summary())\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdf32c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearModelo3D(p,run):        \n",
    "    # Imagen\n",
    "    input_1 = tf.keras.layers.Input(shape=(p['tiempos'][run],p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "    \n",
    "    # Convulutional layers\n",
    "    rescaling = tf.keras.layers.Rescaling(1./65536)(input_1)\n",
    "    conv3d_1 = tf.keras.layers.Conv3D(128, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(rescaling)\n",
    "    #mxPool_1 = tf.keras.layers.MaxPooling3D()(conv3d_1)\n",
    "    dropout_1  = tf.keras.layers.Dropout(0.2)(conv3d_1)\n",
    "    \n",
    "    conv3d_2 = tf.keras.layers.Conv3D(64, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_1)\n",
    "    mxPool_2 = tf.keras.layers.MaxPooling3D()(conv3d_2)\n",
    "    dropout_2  = tf.keras.layers.Dropout(0.1)(mxPool_2)\n",
    "    \n",
    "    #conv2d_3 = tf.keras.layers.Conv3D(32, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_1)\n",
    "    #mxPool_3 = tf.keras.layers.MaxPooling3D()(conv2d_3)\n",
    "    #dropout_3  = tf.keras.layers.Dropout(0.2)(mxPool_3)\n",
    "    \n",
    "    #conv2d_4 = tf.keras.layers.Conv3D(64, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_3)\n",
    "    #mxPool_4 = tf.keras.layers.MaxPooling3D()(conv2d_4)\n",
    "    #dropout_4  = tf.keras.layers.Dropout(0.2)(mxPool_4)\n",
    "    \n",
    "    conv3d_5 = tf.keras.layers.Conv3D(32, kernel_size=3,padding='same',activation=tf.keras.activations.relu)(dropout_2)\n",
    "    \n",
    "    \n",
    "    # Flatten layer :\n",
    "    flatten = tf.keras.layers.Flatten()(conv3d_5)\n",
    "    \n",
    "    final = flatten\n",
    "    listConcat = [flatten]\n",
    "    listInputs = [input_1]\n",
    "    \n",
    "    if len(p['inputs'])>1:\n",
    "        #Agregamos los otros atrbutos        \n",
    "        for attr in p['inputs'][1:]:\n",
    "            # The other input\n",
    "            input_x = tf.keras.layers.Input(shape=(1,))\n",
    "            listConcat.append(input_x)\n",
    "            listInputs.append(input_x)\n",
    "\n",
    "            \n",
    "        # Concatenate\n",
    "        final = tf.keras.layers.Concatenate()(listConcat)\n",
    "        \n",
    "    dense_1 = tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu)(final)\n",
    "    #dense_2 = tf.keras.layers.Dense(units=16, activation=tf.keras.activations.relu)(dense_1)\n",
    "    dense_3 = tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu)(dense_1)\n",
    "    \n",
    "        \n",
    "    # output\n",
    "    if p['redTipo'] == 'regresion':\n",
    "        output = tf.keras.layers.Dense(units=1)(dense_3)\n",
    "        dimOutput = 1\n",
    "    elif p['redTipo'] == 'clasificacion':\n",
    "        output = tf.keras.layers.Dense(units=1,activation=tf.keras.activations.sigmoid)(dense_3)#units=1, activation=tf.keras.activations.relu)(dense_3)\n",
    "        dimOutput = 2\n",
    "    else:\n",
    "        print(f\"No se pudo crear el modelo outputs no esta bien definido {p['redTipo']}\")\n",
    "        return -1      \n",
    "    \n",
    "\n",
    "    full_model = tf.keras.Model(inputs=listInputs, outputs=[output])\n",
    "        \n",
    "    #print(full_model.summary())\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99f33adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearModelo(params,run):    \n",
    "    if params['meanMatrizImagen']:\n",
    "        #print(f\"Creando modelo 2D\")\n",
    "        #print(f\"HP :(T:{params['tiempos'][run]} - M:{params['margen'][run]} - C:{params['canales'][run]}) y  tipo ({params['redTipo']})\")\n",
    "        modelo = crearModelo2D(params,run)\n",
    "    else:\n",
    "        #print(f\"Creando modelo 3D\")\n",
    "        #print(f\"HP :(T:{params['tiempos'][run]} - M:{params['margen'][run]} - C:{params['canales'][run]}) y  tipo ({params['redTipo']})\")\n",
    "        modelo = crearModelo3D(params,run)\n",
    "\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbfb1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos un filename tensor en una imagen\n",
    "def read_png_file(item, value, p,run, path_base, products, times):\n",
    "    # imagenData[0] = XO     # imagenData[1] = XA     # imagenData[2] = Fecha\n",
    "    imagenData = tf.strings.split(item['imagen'], sep='--')\n",
    "    size = int(p['margen'][run] / 2)\n",
    "\n",
    "    timeJoin = []\n",
    "    for j in range(p['tiempos'][run]-1,-1,-1):\n",
    "        filename = path_base + 'PNG/' + imagenData[2] + '/' + imagenData[2] + '_' + str(j) + '.png'\n",
    "        \n",
    "        image_string = tf.io.read_file(filename)\n",
    "\n",
    "        img_decoded = tf.io.decode_png(image_string, dtype=tf.uint16, channels=3)\n",
    "        \n",
    "        \n",
    "                \n",
    "        timeJoin.insert(0,img_decoded[int(imagenData[1]) - size:int(imagenData[1]) + size,\n",
    "                                      int(imagenData[0]) - size:int(imagenData[0]) + size,\n",
    "                                      0:p['canales'][run]])\n",
    " \n",
    "        \n",
    "    if p['tiempos'][run]==1:\n",
    "        imagenData = tf.reshape(timeJoin[0],(p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "    else:\n",
    "        if p['meanMatrizImagen']:        \n",
    "            img = tf.reduce_mean( timeJoin , axis=0 )\n",
    "            imagenData = tf.reshape(img,(p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "        else:\n",
    "            img = tf.stack(timeJoin, axis=0)\n",
    "            imagenData = tf.reshape(img,(p['tiempos'][run],p['margen'][run],p['margen'][run],p['canales'][run]))\n",
    "        \n",
    "    \n",
    "    \n",
    "    if len(p['inputs']) == 1:\n",
    "        return imagenData, int(value)\n",
    "    \n",
    "    item['imagen'] = imagenData\n",
    "    itemL = []\n",
    "    for inpL in p['inputs']:\n",
    "        itemL.append(item[inpL])\n",
    "    \n",
    "    return tuple(itemL), int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cfc22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluarModelo(dsPruebas,modelo, p_train):\n",
    "    inputsList = {}\n",
    "    for inp in p_train['inputs']:\n",
    "        inputsList[inp] = dsPruebas[inp].tolist()       \n",
    "\n",
    "    dsP = tf.data.Dataset.from_tensor_slices(((inputsList),dsPruebas[p_train['outputs']].tolist()))      \n",
    "    dsP = dsP.map(lambda x ,y : read_png_file(x,y,p_train,0,path_imagenes,products,times))\n",
    "    dsP = dsP.batch(p_train['batch'])#.prefetch(tf.data.AUTOTUNE)  \n",
    "    \n",
    "    hist = modelo.predict(dsP, verbose=1)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "828c19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos el DS validacion\n",
    "def getDataset(path_base, model, dsTipo, dirName):\n",
    "    if 'CLASE' in model.upper():\n",
    "        print(f'Se encontro dataset {dsTipo} para CLASE')\n",
    "        if dsTipo == 'Entrenamiento':\n",
    "            DAName = 'SplitConDA_V1' if '_DA' in dirName else 'SplitSinDA_V1'\n",
    "            dsName =  dirName.split('\\\\')[-2]\n",
    "            pruebasFile = f'{path_base}/Archivos/Dataset/Clasificacion/{dsTipo}/{DAName}/{dsName}.csv' # ClasV1\n",
    "        else:\n",
    "            pruebasFile = f'{path_base}/Archivos/Dataset/Clasificacion/{dsTipo}/ClaseV1_{dsTipo}DS.csv' # ClasV1\n",
    "        inputs = ['imagen', 'dato']\n",
    "        outputs = 'clase'\n",
    "\n",
    "    elif 'EST' in model:\n",
    "        print(f'Se encontro dataset {dsTipo} para EST')\n",
    "        pruebasFile = f'{path_base}/Archivos/Dataset/Regresion/{dsTipo}/Dato_EST_{dsTipo}DS.csv' # Reg EST\n",
    "        inputs = ['imagen']\n",
    "        outputs = 'dato'\n",
    "\n",
    "    elif 'DatoV1' in model:            \n",
    "        print(f'Se encontro dataset {dsTipo} para DatoV1')\n",
    "        pruebasFile = f'{path_base}/Archivos/Dataset/Regresion/{dsTipo}/DatoV1_{dsTipo}DS.csv' # Reg V1\n",
    "        inputs = ['imagen']\n",
    "        outputs = 'dato'\n",
    "    \n",
    "    elif 'Dato_V2' in model:\n",
    "        print(f'Se encontro dataset {dsTipo} para Dato_V2')\n",
    "        pruebasFile = f'{path_base}/Archivos/Dataset/Regresion/{dsTipo}/Dato_V2_{dsTipo}DS.csv' # Reg V2\n",
    "        inputs = ['imagen']\n",
    "        outputs = 'dato'\n",
    "    \n",
    "    elif 'Dato_V3' in model:\n",
    "        print(f'Se encontro dataset {dsTipo} para Dato_V3')\n",
    "        pruebasFile = f'{path_base}/Archivos/Dataset/Regresion/{dsTipo}/Dato_V3_{dsTipo}DS.csv' # Reg V3\n",
    "        inputs = ['imagen']\n",
    "        outputs = 'dato'\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(f\"NO SE PUDO ENCONTRAR DS VALIDACION PARA: {model}\")\n",
    "        return -1 \n",
    "    \n",
    "    return pruebasFile, inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "925b78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(modelType, lr, paciencia):\n",
    "    \n",
    "    if modelType == 'clasificacion':    \n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr) \n",
    "        \n",
    "        #BinaryCrossentropy() #CategoricalCrossentropy()      \n",
    "        loss_fn= keras.losses.BinaryCrossentropy()\n",
    "        train_acc_metric = keras.metrics.BinaryCrossentropy()\n",
    "        val_acc_metric = keras.metrics.BinaryCrossentropy()\n",
    "        if paciencia:\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=paciencia, mode=\"max\")  \n",
    " \n",
    "        \n",
    "        metrics = ['acc', keras.metrics.TruePositives(),\n",
    "                         keras.metrics.TrueNegatives(),\n",
    "                         keras.metrics.FalsePositives(),\n",
    "                         keras.metrics.FalseNegatives()]\n",
    "        \n",
    "\n",
    "    elif modelType == 'regresion':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        loss_fn=keras.losses.MeanSquaredError()\n",
    "        train_acc_metric = keras.metrics.MeanSquaredError()\n",
    "        val_acc_metric = keras.metrics.MeanSquaredError()\n",
    "        if paciencia:\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_mse\", patience=paciencia, mode=\"max\")                                            \n",
    "        metrics = ['mse']\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print('No se pudo crear las metricas')\n",
    "        return -1    \n",
    "         \n",
    "        \n",
    "    logs = Callback()\n",
    "    callbacks = [logs]                     \n",
    "    if paciencia:\n",
    "        callbacks.append(early_stopping)\n",
    "        \n",
    "    metrics = {'optimizer': optimizer, 'loss_fn':loss_fn,'train_acc_metric': train_acc_metric,\n",
    "               'val_acc_metric': val_acc_metric, 'metrics': metrics,'callbacks': callbacks}\n",
    "    \n",
    "    return metrics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d63a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelbyID(path_base, idModel, dsTipo = 'Pruebas',inputs=['imagen', 'dato'], graficas=True, epoca=0, dfPruebas=pd.DataFrame()):       \n",
    "    \n",
    "    # Buscamos el modelo en el path_base\n",
    "    os.chdir(f'{path_base}/Archivos/Resultados/')\n",
    "    listFiles = list(glob.glob('**/**/**/*.hdf5'))\n",
    "    #print(f'Cantidad de modelos a buscar: {len(listFiles)}')          \n",
    "    \n",
    "    models = [x for x in listFiles if str(idModel) in x]    \n",
    "    if epoca:         \n",
    "        \n",
    "        models = [x for x in models if f'Model_{epoca:02d}_' in x]\n",
    "        if len(models)<1:\n",
    "            print(f\" No se encontro el modelo {idModel} para la epoca {epoca}\")\n",
    "            return\n",
    "        \n",
    "    if len(models) > 0: \n",
    "        \n",
    "        redTipo = models[0].split('\\\\')[0]        \n",
    "       \n",
    "        if not dfPruebas.empty:\n",
    "            print('Se usara las pruebas asignadas manualmente...')\n",
    "            dsPruebas = dfPruebas\n",
    "            inputs = ['imagen','dato']\n",
    "            outputs = 'clase'\n",
    "        else:\n",
    "            print('Se usara las pruebas encontradas automaticamente...')\n",
    "            pruebasFile, inputs, outputs = getDataset(path_base, models[0], dsTipo, models[0])\n",
    "            dsPruebas = pd.read_csv(pruebasFile)        \n",
    "         \n",
    "\n",
    "        # Buscamos sus parametros\n",
    "        pathStats = f'{path_base}/Archivos/Reportes/Entrenamiento/{redTipo}/ReporteEstadisticas.csv'\n",
    "        try:\n",
    "            stats = pd.read_csv(pathStats)        \n",
    "            modelStats = stats[stats['idModel']==idModel].iloc[0]\n",
    "            print(f'Estadisticas para modelo encontrado: Tipo {redTipo}')\n",
    "        except:\n",
    "            print('No se pudo encontrar el archivo de stats o leer el id del modelo en el archivo stats')\n",
    "            print(f'Archivo leido : {pathStats}')\n",
    "            return -1\n",
    "\n",
    "        C = modelStats['C']  \n",
    "        T = modelStats['T']\n",
    "        M = modelStats['M']\n",
    "        \n",
    "        p_train = {         \n",
    "                # Datos del modelo\n",
    "              'redTipo'  : redTipo.lower(), \n",
    "              'inputs'   : inputs, \n",
    "              'meanMatrizImagen' : not modelStats['3D'], \n",
    "              'outputs'  : outputs, \n",
    "              'num_class': 2,\n",
    "\n",
    "               # Hiper parametros \n",
    "              'canales'  : [int(C)],\n",
    "              'tiempos'  : [int(T)],\n",
    "              'margen'   : [int(M)],\n",
    "              'runs'     : 1,\n",
    "            \n",
    "              # Entrenamiento\n",
    "              'batch'    : 32,\n",
    "              'lr'       : 0.001,\n",
    "         }\n",
    "                \n",
    "        \n",
    "        modelo = crearModelo(p_train,0)\n",
    "        modelo.load_weights(models[0])        \n",
    "        metricas = getMetrics(redTipo.lower(),p_train['lr'], 7)                \n",
    "        modelo.compile(optimizer=metricas['optimizer'],loss=metricas['loss_fn'],metrics=metricas['metrics'],)        \n",
    "        \n",
    "        # Buscamos si se existe la evaluacion\n",
    "        try:\n",
    "            hist = pd.read_csv(f'{path_base}/Archivos/Reportes/Pruebas/{epoca}_{idModel}_{dsTipo}.csv')\n",
    "            #hist = hist['valores'].tolist()            \n",
    "        except:\n",
    "            print(F\"No se encontro resultados en reportes ...procediendo a generar resultados {epoca}-{idModel}-{dsTipo}.csv\")\n",
    "            hist = evaluarModelo(dsPruebas,modelo, p_train)            \n",
    "            hist = pd.DataFrame({'valores': hist.flatten().tolist()})\n",
    "            hist.to_csv(f'{path_base}/Archivos/Reportes/Pruebas/{epoca}_{idModel}_{dsTipo}.csv', index=False)\n",
    "        \n",
    "        \n",
    "        if graficas:                       \n",
    "            if redTipo.lower() == 'regresion':               \n",
    "            \n",
    "                # Dispersion de valores predichos\n",
    "                plt.scatter(dsPruebas['dato'].tolist(), hist['valores'].tolist())\n",
    "                plt.title('DISPERSION DE VALORES REALES VS PREDICHOS ')\n",
    "                plt.xlabel('True Values ')\n",
    "                plt.ylabel('Predictions Values')\n",
    "                plt.show()\n",
    "\n",
    "                #Errores\n",
    "                error = np.array(hist['valores'].tolist()) - np.array(dsPruebas['dato'].tolist())\n",
    "                plt.title('HISTOGRAMA DE ERROR VS CANTIDAD')\n",
    "                plt.hist(error, bins = 25)\n",
    "                plt.xlabel(\"Prediction Error [MPG]\")\n",
    "                plt.ylabel(\"COUNT\")\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "                # Grafico del dataset\n",
    "                dsPruebas['dato'].hist(legend=True) \n",
    "                plt.xlabel('Valores')\n",
    "                plt.ylabel('Cantidad')\n",
    "                print('HISTOGRAMA DE DATASET USADO PARA PREDECIR')\n",
    "                print(f'Cantidad total: {dsPruebas[\"dato\"].count()}')\n",
    "                print(f'Cantidad ceros: {dsPruebas[dsPruebas[\"dato\"]==0][\"dato\"].count()}')\n",
    "                plt.show()                \n",
    "            else:\n",
    "                # Dispersion de valores predichos\n",
    "                dsPruebas['valores'] = hist['valores'].tolist()\n",
    "                _ds0 = dsPruebas[dsPruebas['clase']==0]\n",
    "                _ds1 = dsPruebas[dsPruebas['clase']==1]\n",
    "                \n",
    "                plt.scatter(_ds0['dato'].tolist(), _ds0['valores'].tolist(), label='CLASE 0', c='r')\n",
    "                plt.scatter(_ds1['dato'].tolist(), _ds1['valores'].tolist(), label='CLASE 1' , c = 'b')\n",
    "                plt.legend()\n",
    "                \n",
    "                plt.title('DISPERSION DE Dato vs Prediccion (TOTAL) ')\n",
    "                plt.xlabel('DATO')\n",
    "                plt.ylabel('VALORES')\n",
    "                #plt.xscale(\"log\")   \n",
    "                #plt.yscale(\"log\") \n",
    "                plt.show()\n",
    "                \n",
    "                 # Dispersion de valores predichos (Clase0)\n",
    "                dsPruebas['valores'] = hist['valores'].tolist()\n",
    "                _ds0 = dsPruebas[dsPruebas['clase']==0]\n",
    "                           \n",
    "                plt.scatter(_ds0['dato'].tolist(), _ds0['valores'].tolist(), label='CLASE 0', c='r', alpha=0.2)             \n",
    "                plt.legend()\n",
    "                \n",
    "                plt.title('DISPERSION DE Dato vs Prediccion CLASE 0')\n",
    "                plt.xlabel('DATO')\n",
    "                plt.ylabel('VALORES')\n",
    "                #plt.xscale(\"log\")   \n",
    "                #plt.yscale(\"log\") \n",
    "                plt.show()\n",
    "                \n",
    "                 # Dispersion de valores predichos (Clase1)\n",
    "                dsPruebas['valores'] = hist['valores'].tolist() \n",
    "                _ds1 = dsPruebas[dsPruebas['clase']==1]\n",
    "                          \n",
    "                plt.scatter(_ds1['dato'].tolist(), _ds1['valores'].tolist(), label='CLASE 1', c='b',alpha=0.2)\n",
    "                plt.legend()\n",
    "                \n",
    "                plt.title('DISPERSION DE Dato vs Prediccion CLASE 1')\n",
    "                plt.xlabel('DATO')\n",
    "                plt.ylabel('VALORES')\n",
    "                #plt.xscale(\"log\")   \n",
    "                #plt.yscale(\"log\") \n",
    "                plt.show()\n",
    "\n",
    "        \n",
    "        return hist,dsPruebas#modelo, p_train, hist, dsPruebas\n",
    "        \n",
    "    else:\n",
    "        print(f'No se encontro el modelo con id {idModel} en la PC')\n",
    "        return -1\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c04cc65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModels(path_base, dfModel, dsTipo='Validacion', verb = 5, graficas= True, dfPruebas=pd.DataFrame()): \n",
    "    modeloResultado = []\n",
    "    contador = 0\n",
    "    start_time = time.time()\n",
    "    print(f'Modelo a procesar: {len(dfModel)}')\n",
    "    for i in dfModel.index:\n",
    "        contador = contador + 1\n",
    "        if not contador % verb:\n",
    "            if graficas:\n",
    "                print(f'Se ha procesado {contador} modelo(s) / {len(dfModel)} en %.5fs' %(time.time() - start_time))\n",
    "            \n",
    "        modeloResultado.append(getModelbyID(path_base,dfModel['idModel'][i],dsTipo=dsTipo,epoca=dfModel['epoca'][i],graficas=graficas, dfPruebas=dfPruebas)[0])\n",
    "        \n",
    "        \n",
    "    return modeloResultado    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba0beb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mayoriaVotos(arr, umbrales=[0.5,0.5]):\n",
    "    umbral1 = umbrales[0] \n",
    "    umbral0 = 1 - umbrales[1]\n",
    "    \n",
    "    \n",
    "    arr[arr<umbral0]=0\n",
    "    arr[arr>umbral1]=1\n",
    "    arr[(arr>=umbral0) & (arr<=umbral1)] = 2\n",
    "    arr= arr.astype(int)\n",
    "    counts = np.bincount(arr)\n",
    "    \n",
    "    return np.argmax(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b876f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficaJoinedStats(df):   \n",
    "    dfMet0 = df[df['MET']=='mean']\n",
    "    dfMet1 = df[df['MET']=='voto']\n",
    "    \n",
    "\n",
    "    cm0 = [[dfMet0['TP'].iloc[0],dfMet0['FN'].iloc[0]],\n",
    "          [dfMet0['FP'].iloc[0],dfMet0['TN'].iloc[0]]]\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=np.array(cm0),\n",
    "                                       display_labels=['M02','C02'])\n",
    "        \n",
    "    disp.plot()\n",
    "    plt.title(f'Matriz de Confusion para metodo 0 (Media Aritmetica)')\n",
    "    plt.show()  \n",
    "    \n",
    "    \n",
    "    cm1 = [[dfMet1['TP'].iloc[0],dfMet1['FN'].iloc[0]],\n",
    "          [dfMet1['FP'].iloc[0],dfMet1['TN'].iloc[0]]]\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=np.array(cm1),\n",
    "                                       display_labels=['M02','C02'])\n",
    "    disp.plot()\n",
    "    plt.title(f'Matriz de Confusion para metodo 1 (Voto Mayoritario)')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2110072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficaHistStats(df):    \n",
    "    \n",
    "    dfMet0 = df[df['MET']=='mean']\n",
    "    dfMet1 = df[df['MET']=='voto']\n",
    "    \n",
    "    #      C02   M02   DUD\n",
    "    met1 = [dfMet0['C02'].iloc[0],\n",
    "            dfMet0['M02'].iloc[0],\n",
    "            dfMet0['DUD'].iloc[0]]\n",
    "    \n",
    "    met0 = [dfMet1['C02'].iloc[0],\n",
    "            dfMet1['M02'].iloc[0],\n",
    "            dfMet1['DUD'].iloc[0]]\n",
    "\n",
    "    r = np.arange(3)\n",
    "    width = 0.25\n",
    "\n",
    "\n",
    "    plt.bar(r, met0, width = width, label='Metodo 0 (Mean)')\n",
    "    plt.bar(r + width, met1, width = width,label='Metodo 1 (Voto)')\n",
    "\n",
    "    plt.xlabel(\"Clasificacion\")\n",
    "    plt.ylabel(\"Cantidad\")\n",
    "    plt.title(\"Clasificacion de los valores predichos por metodo\")\n",
    "\n",
    "    plt.grid(linestyle='--')\n",
    "    plt.xticks(r + width/2,['C02','M02','DUD'])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3d205d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatsResult(df):\n",
    "    \n",
    "    dfnoDud0 = df[df['pred0']!=2]\n",
    "    dfnoDud1 = df[df['pred1']!=2]\n",
    "    \n",
    "    \n",
    "    tn0, fp0, fn0, tp0 = confusion_matrix(dfnoDud0['real'], dfnoDud0['pred0']).ravel()\n",
    "    tn1, fp1, fn1, tp1 = confusion_matrix(dfnoDud1['real'], dfnoDud1['pred1']).ravel()\n",
    "    \n",
    "    dictDF = {'MET':['mean','voto'],'TN':[tn0,tn1],'FP':[fp0,fp1], 'FN':[fn0,fn1],\n",
    "              'TP':[tp0,tp1], 'DUD' : [len(df)-len(dfnoDud0), len(df)-len(dfnoDud1)],\n",
    "              'C02': [len(dfnoDud0[dfnoDud0['pred0']==1]) , len(dfnoDud1[dfnoDud1['pred1']==1])],\n",
    "              'M02': [len(dfnoDud0[dfnoDud0['pred0']==0]) , len(dfnoDud0[dfnoDud0['pred0']==0])]\n",
    "             }\n",
    "    result = pd.DataFrame(dictDF)\n",
    "    \n",
    "    result['TNR'] = result['TN'] / (result['TN']+result['FP'])\n",
    "    result['TPR'] =    result['TP'] / (result['TP']+result['FN'])\n",
    "    result['acc_bal'] =  (result['TNR'] + result['TPR']) / 2 \n",
    "    \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f17f90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo 0 =  mean\n",
    "# metodo 1 = voto\n",
    "\n",
    "#Umbrales = [C02,M02]\n",
    "\n",
    "def getJoinStats(path_base, project, criterio='Validacion',dsTipo='Validacion', umbrales=[0.5,0.5]):\n",
    "    print('-----------------------------------------------')\n",
    "    print(f'\\n ESTADISTICAS PARA PROYECTO {project}')\n",
    "    print(f'Criterio para mejor estadisticas  : {criterio}')\n",
    "    print(f'Dataset usado para estadisticas   : {dsTipo}')\n",
    "    print(f'Umbrales C02: {umbrales[0]} - M02: {1-umbrales[1]}')\n",
    "    print('-----------------------------------------------')\n",
    "    \n",
    "    # DF PRUEBAS\n",
    "    filePruebas = f'{path_base}/Archivos/Dataset/Clasificacion/{dsTipo}/ClaseV2_DUD_{dsTipo}DS.csv'\n",
    "    try:\n",
    "        dfPruebas = pd.read_csv(filePruebas)\n",
    "    except:\n",
    "        print(f'No se pudo leer el archiv de {dsTipo} en el proyecto {project} ...')\n",
    "        return \n",
    "\n",
    "    # DF MODELS\n",
    "    fileModels = f'{path_base}/Archivos/Reportes/Entrenamiento/Clasificacion/{project}_{criterio}.csv'\n",
    "    try:\n",
    "        dfModel = pd.read_csv(fileModels)\n",
    "    except:\n",
    "        print(f'No se pudo leer el archiv de {project} con {criterio} stats...')\n",
    "        return \n",
    "    \n",
    "    listResult = testModels(path_base, dfModel, dsTipo=dsTipo, verb = 1, graficas=False, dfPruebas=dfPruebas)\n",
    "    #return listResult, dfPruebas\n",
    "    \n",
    "    lenDS =  len(listResult)\n",
    "    numTest = len(listResult[0])    \n",
    "    \n",
    "    \n",
    "    dictResult = {'valor':[],'real':[],'pred0':[],'pred1':[]}\n",
    "    \n",
    "    for j in range(numTest):\n",
    "        dictResult['real'].append(dfPruebas['clase'][j])\n",
    "        dictResult['valor'].append(dfPruebas['dato'][j])\n",
    "        \n",
    "        valorPred = []\n",
    "        for i in range(lenDS):\n",
    "            valorPred.append(listResult[i]['valores'][j])\n",
    "            \n",
    "        valorPred = np.array(valorPred)  \n",
    "        mean = valorPred.mean()\n",
    "        if mean<=(umbrales[0]) and mean>=(1-umbrales[1]):\n",
    "            valMean = 2\n",
    "        elif mean>umbrales[0]:\n",
    "            valMean = 1\n",
    "        else:\n",
    "            valMean = 0        \n",
    "        \n",
    "        dictResult['pred0'].append(valMean)\n",
    "        dictResult['pred1'].append(mayoriaVotos(valorPred, umbrales))\n",
    "    \n",
    "    dfResult = pd.DataFrame(dictResult)  \n",
    "    dfStats = getStatsResult(dfResult)    \n",
    "    \n",
    "    graficaHistStats(dfStats)       \n",
    "    graficaJoinedStats(dfStats)        \n",
    "    \n",
    "    return dfResult, dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2b193fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficaScatterPrediciones(df, flag='M02',metodo=0, dudosos=True):\n",
    "    if metodo in [0,'mean']:\n",
    "        columna = 'pred0'\n",
    "        met = [0,'Mean']\n",
    "    else:\n",
    "        columna = 'pred1'\n",
    "        met = [1,'Voto']\n",
    "        \n",
    "    if flag in [0,'M02']:\n",
    "        fl = [0,'M02']\n",
    "    elif flag in [1,'C02']:\n",
    "        fl = [1,'C02']\n",
    "    else:\n",
    "        print('Flags posibles: [0,1,C02,M02]')\n",
    "        return\n",
    "    \n",
    "    dfnoD = df[df[columna]!=2]\n",
    "    dfD = df[df[columna]==2]\n",
    "    dfTrue = dfnoD[(dfnoD[columna]==fl[0]) & (dfnoD['real']==fl[0])]\n",
    "    dfFalse = dfnoD[(dfnoD[columna]!=fl[0]) & (dfnoD['real']==fl[0])]\n",
    "    \n",
    "    print(f'Estadisticas para el flag {fl[1]} con el metodo {met[1]}')\n",
    "    print(f'Cantidad de datos total    : {len(dfTrue) + len(dfFalse)}')\n",
    "    print(f'Cantidad de datos correctos: {len(dfTrue)}')\n",
    "    print(f'Cantidad de datos erroneos : {len(dfFalse)}')\n",
    "    print(f'Cantidad de datos dudosos  : {len(dfD)}')\n",
    "    \n",
    "    plt.scatter(dfTrue['valor'].tolist(), dfTrue[columna].tolist(), label=f'{fl[1]}_True'  , marker='.' ,c = 'g', alpha=0.3)\n",
    "    plt.scatter(dfFalse['valor'].tolist(), dfFalse[columna].tolist(), label=f'{fl[1]}_False' , marker='X' ,c = 'r', alpha=0.6)\n",
    "    if dudosos:\n",
    "        plt.scatter(dfD['valor'].tolist(), dfD[columna].tolist(), label=f'{fl[1]}_DUD' , marker='1' ,c = 'b', alpha=0.6)\n",
    "    \n",
    "    plt.legend(loc=(1.1,0)) \n",
    "\n",
    "    plt.title(f'Real vs Predicho ({fl[1]})')\n",
    "    plt.xlabel('DATO')\n",
    "    plt.ylabel('VALORES') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e2078e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "\n",
      " ESTADISTICAS PARA PROYECTO Clasificacion_DUD_3D_DA\n",
      "Criterio para mejor estadisticas  : Validacion\n",
      "Dataset usado para estadisticas   : Validacion\n",
      "Umbrales C02: 0.5 - M02: 0.5\n",
      "-----------------------------------------------\n",
      "Modelo a procesar: 16\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 0-20220526_082937-Validacion.csv\n",
      "101/101 [==============================] - 74s 724ms/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 2-20220526_095500-Validacion.csv\n",
      "101/101 [==============================] - 73s 721ms/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 13-20220526_122448-Validacion.csv\n",
      "101/101 [==============================] - 104s 1s/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 11-20220526_132020-Validacion.csv\n",
      "101/101 [==============================] - 125s 1s/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 8-20220526_145713-Validacion.csv\n",
      "101/101 [==============================] - 111s 1s/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 4-20220526_164106-Validacion.csv\n",
      "101/101 [==============================] - 73s 723ms/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 12-20220526_180834-Validacion.csv\n",
      "101/101 [==============================] - 73s 720ms/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 14-20220526_200745-Validacion.csv\n",
      "101/101 [==============================] - 74s 727ms/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 10-20220526_214257-Validacion.csv\n",
      "101/101 [==============================] - 74s 728ms/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 7-20220526_232044-Validacion.csv\n",
      "101/101 [==============================] - 74s 727ms/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 0-20220527_010354-Validacion.csv\n",
      "101/101 [==============================] - 131s 1s/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 0-20220527_022322-Validacion.csv\n",
      "101/101 [==============================] - 130s 1s/step\n",
      "Se usara las pruebas asignadas manualmente...\n",
      "Estadisticas para modelo encontrado: Tipo Clasificacion\n",
      "No se encontro resultados en reportes ...procediendo a generar resultados 10-20220527_034632-Validacion.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36mgetModelbyID\u001b[1;34m(path_base, idModel, dsTipo, inputs, graficas, epoca, dfPruebas)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath_base\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Archivos/Reportes/Pruebas/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoca\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midModel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdsTipo\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m#hist = hist['valores'].tolist()            \u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/NewTesis/Archivos/Reportes/Pruebas/10_20220527_034632_Validacion.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClasificacion_DUD_3D_DA\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Umbrales(C02,M02)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m results, stats \u001b[38;5;241m=\u001b[39m \u001b[43mgetJoinStats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValidacion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdsTipo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValidacion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumbrales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m stats\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mgetJoinStats\u001b[1;34m(path_base, project, criterio, dsTipo, umbrales)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo se pudo leer el archiv de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m con \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcriterio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m stats...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \n\u001b[1;32m---> 30\u001b[0m listResult \u001b[38;5;241m=\u001b[39m \u001b[43mtestModels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsTipo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdsTipo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraficas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfPruebas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdfPruebas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#return listResult, dfPruebas\u001b[39;00m\n\u001b[0;32m     33\u001b[0m lenDS \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mlen\u001b[39m(listResult)\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mtestModels\u001b[1;34m(path_base, dfModel, dsTipo, verb, graficas, dfPruebas)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m graficas:\n\u001b[0;32m     10\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe ha procesado \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontador\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m modelo(s) / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dfModel)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m en %.5fs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m---> 12\u001b[0m     modeloResultado\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgetModelbyID\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdfModel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midModel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdsTipo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdsTipo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdfModel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgraficas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraficas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfPruebas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdfPruebas\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modeloResultado\n",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36mgetModelbyID\u001b[1;34m(path_base, idModel, dsTipo, inputs, graficas, epoca, dfPruebas)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo se encontro resultados en reportes ...procediendo a generar resultados \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoca\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midModel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdsTipo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mevaluarModelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsPruebas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_train\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[0;32m     78\u001b[0m     hist \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalores\u001b[39m\u001b[38;5;124m'\u001b[39m: hist\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()})\n\u001b[0;32m     79\u001b[0m     hist\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Archivos/Reportes/Pruebas/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoca\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midModel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdsTipo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mevaluarModelo\u001b[1;34m(dsPruebas, modelo, p_train)\u001b[0m\n\u001b[0;32m      7\u001b[0m dsP \u001b[38;5;241m=\u001b[39m dsP\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x ,y : read_png_file(x,y,p_train,\u001b[38;5;241m0\u001b[39m,path_imagenes,products,times))\n\u001b[0;32m      8\u001b[0m dsP \u001b[38;5;241m=\u001b[39m dsP\u001b[38;5;241m.\u001b[39mbatch(p_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;66;03m#.prefetch(tf.data.AUTOTUNE)  \u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hist\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\keras\\engine\\training.py:1982\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1980\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1981\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 1982\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1983\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1984\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:986\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    982\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    983\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    985\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[0;32m    990\u001b[0m   \u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WB-PY39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "project = 'Clasificacion_DUD_3D_DA'\n",
    "# Umbrales(C02,M02)\n",
    "results, stats = getJoinStats(path_base, project, criterio='Validacion',dsTipo='Validacion', umbrales=[0.5,0.5]) \n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graficaScatterPrediciones(results, flag='M02',metodo='mean', dudosos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graficaScatterPrediciones(results, flag='C02',metodo='mean', dudosos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5d254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clasificacion_3D_DA_ANAV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
